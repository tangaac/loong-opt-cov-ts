	.file	"jfdctfst.c"
	.text
	.globl	jpeg_fdct_ifast                 # -- Begin function jpeg_fdct_ifast
	.p2align	5
	.type	jpeg_fdct_ifast,@function
jpeg_fdct_ifast:                        # @jpeg_fdct_ifast
# %bb.0:
	addi.d	$sp, $sp, -192
	st.d	$ra, $sp, 184                   # 8-byte Folded Spill
	st.d	$fp, $sp, 176                   # 8-byte Folded Spill
	addi.d	$fp, $sp, 192
	bstrins.d	$sp, $zero, 4, 0
	addi.w	$a2, $zero, -8
	ori	$a1, $zero, 181
	ori	$a3, $zero, 98
	ori	$a4, $zero, 139
	ori	$a5, $zero, 334
	ori	$a6, $zero, 0
	lu32i.d	$a6, 1
	move	$a7, $a0
	.p2align	4, , 16
.LBB0_1:                                # =>This Inner Loop Header: Depth=1
	ld.w	$t0, $a7, 0
	ld.w	$t1, $a7, 28
	ld.w	$t2, $a7, 4
	ld.w	$t3, $a7, 24
	add.d	$t4, $t1, $t0
	sub.d	$t0, $t0, $t1
	add.d	$t1, $t3, $t2
	ld.w	$t5, $a7, 8
	ld.w	$t6, $a7, 20
	ld.w	$t7, $a7, 12
	ld.w	$t8, $a7, 16
	sub.d	$t2, $t2, $t3
	add.d	$t3, $t6, $t5
	sub.d	$t5, $t5, $t6
	add.d	$t6, $t8, $t7
	sub.d	$t7, $t7, $t8
	add.d	$t8, $t6, $t4
	sub.d	$t4, $t4, $t6
	add.d	$t6, $t3, $t1
	sub.d	$t1, $t1, $t3
	add.d	$t3, $t8, $t6
	st.w	$t3, $a7, 0
	sub.d	$t3, $t8, $t6
	st.w	$t3, $a7, 16
	add.w	$t1, $t1, $t4
	mul.d	$t1, $t1, $a1
	srli.d	$t1, $t1, 8
	add.d	$t3, $t4, $t1
	st.w	$t3, $a7, 8
	sub.d	$t1, $t4, $t1
	st.w	$t1, $a7, 24
	add.w	$t1, $t7, $t5
	add.w	$t3, $t5, $t2
	add.w	$t2, $t2, $t0
	sub.w	$t4, $t1, $t2
	mul.d	$t4, $t4, $a3
	srli.d	$t4, $t4, 8
	mul.d	$t1, $t1, $a4
	srli.d	$t1, $t1, 8
	add.d	$t1, $t4, $t1
	mul.d	$t2, $t2, $a5
	srli.d	$t2, $t2, 8
	add.d	$t2, $t4, $t2
	mul.d	$t3, $t3, $a1
	srli.d	$t3, $t3, 8
	add.d	$t4, $t0, $t3
	sub.d	$t0, $t0, $t3
	add.d	$t3, $t1, $t0
	st.w	$t3, $a7, 20
	sub.d	$t0, $t0, $t1
	st.w	$t0, $a7, 12
	add.d	$t0, $t2, $t4
	st.w	$t0, $a7, 4
	sub.d	$t0, $t4, $t2
	st.w	$t0, $a7, 28
	bstrpick.d	$a2, $a2, 31, 0
	addi.d	$a2, $a2, 1
	and	$t0, $a2, $a6
	addi.d	$a7, $a7, 32
	beqz	$t0, .LBB0_1
# %bb.2:                                # %vector.body
	xvld	$xr0, $a0, 0
	xvld	$xr1, $a0, 224
	xvadd.w	$xr2, $xr1, $xr0
	xvld	$xr3, $a0, 32
	xvld	$xr4, $a0, 192
	xvld	$xr5, $a0, 64
	xvld	$xr6, $a0, 160
	xvld	$xr7, $a0, 96
	xvld	$xr8, $a0, 128
	xvsub.w	$xr0, $xr0, $xr1
	xvadd.w	$xr1, $xr4, $xr3
	xvadd.w	$xr9, $xr6, $xr5
	xvadd.w	$xr10, $xr8, $xr7
	xvadd.w	$xr11, $xr10, $xr2
	xvsub.w	$xr2, $xr2, $xr10
	xvadd.w	$xr10, $xr9, $xr1
	xvsub.w	$xr1, $xr1, $xr9
	xvadd.w	$xr9, $xr11, $xr10
	xvst	$xr9, $a0, 0
	xvsub.w	$xr9, $xr11, $xr10
	xvst	$xr9, $a0, 128
	xvadd.w	$xr1, $xr1, $xr2
	xvst	$xr1, $sp, 128
	vld	$vr1, $sp, 144
	xvsub.w	$xr3, $xr3, $xr4
	xvsub.w	$xr5, $xr5, $xr6
	xvsub.w	$xr4, $xr7, $xr8
	vpickve2gr.w	$a1, $vr1, 0
	xvinsgr2vr.d	$xr6, $a1, 0
	vpickve2gr.w	$a1, $vr1, 1
	xvinsgr2vr.d	$xr6, $a1, 1
	vpickve2gr.w	$a1, $vr1, 2
	vld	$vr7, $sp, 128
	xvinsgr2vr.d	$xr6, $a1, 2
	vpickve2gr.w	$a1, $vr1, 3
	xvinsgr2vr.d	$xr6, $a1, 3
	vpickve2gr.w	$a1, $vr7, 0
	xvinsgr2vr.d	$xr8, $a1, 0
	vpickve2gr.w	$a1, $vr7, 1
	xvinsgr2vr.d	$xr8, $a1, 1
	vpickve2gr.w	$a1, $vr7, 2
	xvinsgr2vr.d	$xr8, $a1, 2
	vpickve2gr.w	$a1, $vr7, 3
	xvinsgr2vr.d	$xr8, $a1, 3
	xvrepli.d	$xr1, 181
	xvmul.d	$xr7, $xr8, $xr1
	xvmul.d	$xr6, $xr6, $xr1
	xvsrli.d	$xr6, $xr6, 8
	xvsrli.d	$xr7, $xr7, 8
	xvpickve2gr.d	$a1, $xr7, 0
	xvinsgr2vr.w	$xr8, $a1, 0
	xvpickve2gr.d	$a1, $xr7, 1
	xvinsgr2vr.w	$xr8, $a1, 1
	xvpickve2gr.d	$a1, $xr7, 2
	xvinsgr2vr.w	$xr8, $a1, 2
	xvpickve2gr.d	$a1, $xr7, 3
	xvinsgr2vr.w	$xr8, $a1, 3
	xvpickve2gr.d	$a1, $xr6, 0
	xvinsgr2vr.w	$xr8, $a1, 4
	xvpickve2gr.d	$a1, $xr6, 1
	xvinsgr2vr.w	$xr8, $a1, 5
	xvpickve2gr.d	$a1, $xr6, 2
	xvinsgr2vr.w	$xr8, $a1, 6
	xvpickve2gr.d	$a1, $xr6, 3
	xvinsgr2vr.w	$xr8, $a1, 7
	xvadd.w	$xr6, $xr2, $xr8
	xvst	$xr6, $a0, 64
	xvsub.w	$xr2, $xr2, $xr8
	xvst	$xr2, $a0, 192
	xvadd.w	$xr6, $xr4, $xr5
	xvadd.w	$xr4, $xr3, $xr0
	xvsub.w	$xr2, $xr6, $xr4
	xvst	$xr2, $sp, 96
	vld	$vr7, $sp, 112
	xvadd.w	$xr2, $xr5, $xr3
	vpickve2gr.w	$a1, $vr7, 0
	xvinsgr2vr.d	$xr3, $a1, 0
	vpickve2gr.w	$a1, $vr7, 1
	xvinsgr2vr.d	$xr3, $a1, 1
	vpickve2gr.w	$a1, $vr7, 2
	vld	$vr5, $sp, 96
	xvinsgr2vr.d	$xr3, $a1, 2
	vpickve2gr.w	$a1, $vr7, 3
	xvinsgr2vr.d	$xr3, $a1, 3
	vpickve2gr.w	$a1, $vr5, 0
	xvinsgr2vr.d	$xr7, $a1, 0
	vpickve2gr.w	$a1, $vr5, 1
	xvinsgr2vr.d	$xr7, $a1, 1
	vpickve2gr.w	$a1, $vr5, 2
	xvinsgr2vr.d	$xr7, $a1, 2
	vpickve2gr.w	$a1, $vr5, 3
	xvinsgr2vr.d	$xr7, $a1, 3
	xvrepli.d	$xr5, 98
	xvmul.d	$xr7, $xr7, $xr5
	xvmul.d	$xr3, $xr3, $xr5
	xvsrli.d	$xr5, $xr3, 8
	xvsrli.d	$xr7, $xr7, 8
	xvpickve2gr.d	$a1, $xr7, 0
	xvinsgr2vr.w	$xr3, $a1, 0
	xvpickve2gr.d	$a1, $xr7, 1
	xvinsgr2vr.w	$xr3, $a1, 1
	xvpickve2gr.d	$a1, $xr7, 2
	xvinsgr2vr.w	$xr3, $a1, 2
	xvpickve2gr.d	$a1, $xr7, 3
	xvinsgr2vr.w	$xr3, $a1, 3
	xvpickve2gr.d	$a1, $xr5, 0
	xvinsgr2vr.w	$xr3, $a1, 4
	xvpickve2gr.d	$a1, $xr5, 1
	xvinsgr2vr.w	$xr3, $a1, 5
	xvpickve2gr.d	$a1, $xr5, 2
	xvst	$xr6, $sp, 0
	vld	$vr6, $sp, 16
	xvinsgr2vr.w	$xr3, $a1, 6
	xvpickve2gr.d	$a1, $xr5, 3
	xvinsgr2vr.w	$xr3, $a1, 7
	vpickve2gr.w	$a1, $vr6, 0
	xvinsgr2vr.d	$xr5, $a1, 0
	vpickve2gr.w	$a1, $vr6, 1
	xvinsgr2vr.d	$xr5, $a1, 1
	vpickve2gr.w	$a1, $vr6, 2
	vld	$vr7, $sp, 0
	xvinsgr2vr.d	$xr5, $a1, 2
	vpickve2gr.w	$a1, $vr6, 3
	xvinsgr2vr.d	$xr5, $a1, 3
	vpickve2gr.w	$a1, $vr7, 0
	xvinsgr2vr.d	$xr6, $a1, 0
	vpickve2gr.w	$a1, $vr7, 1
	xvinsgr2vr.d	$xr6, $a1, 1
	vpickve2gr.w	$a1, $vr7, 2
	xvinsgr2vr.d	$xr6, $a1, 2
	vpickve2gr.w	$a1, $vr7, 3
	xvinsgr2vr.d	$xr6, $a1, 3
	xvrepli.d	$xr7, 139
	xvmul.d	$xr6, $xr6, $xr7
	xvmul.d	$xr5, $xr5, $xr7
	xvsrli.d	$xr5, $xr5, 8
	xvsrli.d	$xr6, $xr6, 8
	xvpickve2gr.d	$a1, $xr6, 0
	xvinsgr2vr.w	$xr7, $a1, 0
	xvpickve2gr.d	$a1, $xr6, 1
	xvinsgr2vr.w	$xr7, $a1, 1
	xvpickve2gr.d	$a1, $xr6, 2
	xvinsgr2vr.w	$xr7, $a1, 2
	xvpickve2gr.d	$a1, $xr6, 3
	xvinsgr2vr.w	$xr7, $a1, 3
	xvpickve2gr.d	$a1, $xr5, 0
	xvinsgr2vr.w	$xr7, $a1, 4
	xvpickve2gr.d	$a1, $xr5, 1
	xvinsgr2vr.w	$xr7, $a1, 5
	xvpickve2gr.d	$a1, $xr5, 2
	xvinsgr2vr.w	$xr7, $a1, 6
	xvst	$xr4, $sp, 64
	vld	$vr6, $sp, 80
	xvpickve2gr.d	$a1, $xr5, 3
	xvinsgr2vr.w	$xr7, $a1, 7
	xvadd.w	$xr4, $xr3, $xr7
	vpickve2gr.w	$a1, $vr6, 0
	xvinsgr2vr.d	$xr5, $a1, 0
	vpickve2gr.w	$a1, $vr6, 1
	xvinsgr2vr.d	$xr5, $a1, 1
	vpickve2gr.w	$a1, $vr6, 2
	vld	$vr7, $sp, 64
	xvinsgr2vr.d	$xr5, $a1, 2
	vpickve2gr.w	$a1, $vr6, 3
	xvinsgr2vr.d	$xr5, $a1, 3
	vpickve2gr.w	$a1, $vr7, 0
	xvinsgr2vr.d	$xr6, $a1, 0
	vpickve2gr.w	$a1, $vr7, 1
	xvinsgr2vr.d	$xr6, $a1, 1
	vpickve2gr.w	$a1, $vr7, 2
	xvinsgr2vr.d	$xr6, $a1, 2
	vpickve2gr.w	$a1, $vr7, 3
	xvinsgr2vr.d	$xr6, $a1, 3
	xvrepli.d	$xr7, 334
	xvmul.d	$xr6, $xr6, $xr7
	xvmul.d	$xr5, $xr5, $xr7
	xvsrli.d	$xr5, $xr5, 8
	xvsrli.d	$xr6, $xr6, 8
	xvpickve2gr.d	$a1, $xr6, 0
	xvinsgr2vr.w	$xr7, $a1, 0
	xvpickve2gr.d	$a1, $xr6, 1
	xvinsgr2vr.w	$xr7, $a1, 1
	xvpickve2gr.d	$a1, $xr6, 2
	xvinsgr2vr.w	$xr7, $a1, 2
	xvpickve2gr.d	$a1, $xr6, 3
	xvinsgr2vr.w	$xr7, $a1, 3
	xvpickve2gr.d	$a1, $xr5, 0
	xvinsgr2vr.w	$xr7, $a1, 4
	xvpickve2gr.d	$a1, $xr5, 1
	xvinsgr2vr.w	$xr7, $a1, 5
	xvpickve2gr.d	$a1, $xr5, 2
	xvinsgr2vr.w	$xr7, $a1, 6
	xvst	$xr2, $sp, 32
	vld	$vr2, $sp, 48
	xvpickve2gr.d	$a1, $xr5, 3
	xvinsgr2vr.w	$xr7, $a1, 7
	xvadd.w	$xr3, $xr3, $xr7
	vpickve2gr.w	$a1, $vr2, 0
	xvinsgr2vr.d	$xr5, $a1, 0
	vpickve2gr.w	$a1, $vr2, 1
	xvinsgr2vr.d	$xr5, $a1, 1
	vpickve2gr.w	$a1, $vr2, 2
	vld	$vr6, $sp, 32
	xvinsgr2vr.d	$xr5, $a1, 2
	vpickve2gr.w	$a1, $vr2, 3
	xvinsgr2vr.d	$xr5, $a1, 3
	vpickve2gr.w	$a1, $vr6, 0
	xvinsgr2vr.d	$xr2, $a1, 0
	vpickve2gr.w	$a1, $vr6, 1
	xvinsgr2vr.d	$xr2, $a1, 1
	vpickve2gr.w	$a1, $vr6, 2
	xvinsgr2vr.d	$xr2, $a1, 2
	vpickve2gr.w	$a1, $vr6, 3
	xvinsgr2vr.d	$xr2, $a1, 3
	xvmul.d	$xr2, $xr2, $xr1
	xvmul.d	$xr1, $xr5, $xr1
	xvsrli.d	$xr1, $xr1, 8
	xvsrli.d	$xr2, $xr2, 8
	xvpickve2gr.d	$a1, $xr2, 0
	xvinsgr2vr.w	$xr5, $a1, 0
	xvpickve2gr.d	$a1, $xr2, 1
	xvinsgr2vr.w	$xr5, $a1, 1
	xvpickve2gr.d	$a1, $xr2, 2
	xvinsgr2vr.w	$xr5, $a1, 2
	xvpickve2gr.d	$a1, $xr2, 3
	xvinsgr2vr.w	$xr5, $a1, 3
	xvpickve2gr.d	$a1, $xr1, 0
	xvinsgr2vr.w	$xr5, $a1, 4
	xvpickve2gr.d	$a1, $xr1, 1
	xvinsgr2vr.w	$xr5, $a1, 5
	xvpickve2gr.d	$a1, $xr1, 2
	xvinsgr2vr.w	$xr5, $a1, 6
	xvpickve2gr.d	$a1, $xr1, 3
	xvinsgr2vr.w	$xr5, $a1, 7
	xvadd.w	$xr1, $xr0, $xr5
	xvsub.w	$xr0, $xr0, $xr5
	xvadd.w	$xr2, $xr4, $xr0
	xvst	$xr2, $a0, 160
	xvsub.w	$xr0, $xr0, $xr4
	xvst	$xr0, $a0, 96
	xvadd.w	$xr0, $xr3, $xr1
	xvst	$xr0, $a0, 32
	xvsub.w	$xr0, $xr1, $xr3
	xvst	$xr0, $a0, 224
	addi.d	$sp, $fp, -192
	ld.d	$fp, $sp, 176                   # 8-byte Folded Reload
	ld.d	$ra, $sp, 184                   # 8-byte Folded Reload
	addi.d	$sp, $sp, 192
	ret
.Lfunc_end0:
	.size	jpeg_fdct_ifast, .Lfunc_end0-jpeg_fdct_ifast
                                        # -- End function
	.section	".note.GNU-stack","",@progbits
	.addrsig
